{

{-# OPTIONS_GHC -fno-warn-deprecated-flags
                -fno-warn-lazy-unlifted-bindings #-}
-- | TODO
--
--  * Unicode support: see GHC lexer and Agda lexer (the latter seems simpler)

module CICwf.Syntax.Lexer where

import Control.Monad.State

import Data.Char
import Data.Word (Word8)

import CICwf.Syntax.Tokens
import CICwf.Syntax.Alex
import CICwf.Syntax.ParseMonad
import CICwf.Syntax.Position

}

$digit = 0-9
$alpha = [ a-z A-Z _ ]

@number = $digit+
@ident = $alpha [ $alpha $digit \' ]*

tokens :-

  $white+       ;

  -- One-line and nested comments
  "--"       { \_ _ -> skipOneLineComment }
  "{-"       { \_ _ -> skipNestedComment }

  fix @number       { fixKeyword }
  Type @number      { typeKeyword }

  \(          { symbol }
  \)          { symbol }
  \\          { ident  }
  "->"        { symbol }
  "=>"        { symbol }
  "<="        { symbol }
  ","         { symbol }
  ":="        { symbol }
  "."         { symbol }
  ":"         { symbol }
  "::"        { symbol }
  "|"         { symbol }
  "+"         { symbolOrOther }
  "-"         { symbol }
  "++"        { symbol }
  "@"         { symbol }
  "*"         { symbol }
  "<"         { symbol }
  ">"         { symbol }
  "["         { symbol }
  "]"         { symbol }
  "{"         { symbol }
  "}"         { symbol }

  @ident      { ident }
  @ident "*"  { identStar }

  "!" @ident  { liftedIdent }

  @number     { number }
{

-- wraps the Lexer generated by alex into the monad Parser

lexToken :: Parser Token
lexToken =
  do inp <- getLexerInput
     case alexScan (foolAlex inp) 0 of  -- 0 is the state of the lexer. Not used now
       AlexEOF -> return TokEOF
       AlexError err -> parseErrorAt (lexPos inp) ("Lexical error : " ++ lexInput err) -- rest of input ingnored at the moment
       AlexSkip inp' len -> putLexerInput (newInput inp inp' len) >> lexToken
       AlexToken inp' len act ->
         do putLexerInput (newInput inp inp' len)
            act (lexPos inp) (take len (lexInput inp))

-- Stolen from Agda

-- newInput undoes the effect of foolAlex
-- | Use the input string from the previous input (with the appropriate
--   number of characters dropped) instead of the fake input string that
--   was given to Alex (with unicode characters removed).
newInput :: PreviousInput -> CurrentInput -> TokenLength -> CurrentInput
newInput inp inp' len =
    case drop (len - 1) (lexInput inp) of
	c:s'	-> inp' { lexInput    = s'
			, lexPrevChar = c
			}
	[]	-> inp' { lexInput = [] }

-- | Alex 2 can't handle unicode characters. To solve this we
--   translate all Unicode (non-ASCII) identifiers to @z@, all Unicode
--   operator characters to @+@, and all whitespace characters (except
--   for @\t@ and @\n@) to ' '. It is important that there aren't any
--   keywords containing @z@, @+@ or @ @.
foolAlex :: AlexInput -> AlexInput
foolAlex inp = inp { lexInput = map fool $ lexInput inp }
    where
	fool c
            | isSpace c && not (c `elem` "\t\n") = ' '
            -- --| c `elem` ['\x2080'..'\x2089'] {- ₀..₉ -} = '1'
            | c == '\x03a0' {- Π -} = '+'
            | c == '\x03bb' {- λ -} = '+'
	    | isUnicodeId c         = if isAlpha c then 'z' else '+'
	    | otherwise             = c
        isUnicodeId :: Char -> Bool
        isUnicodeId c = isPrint c && not (isAscii c)

lexer :: (Token -> Parser a) -> Parser a
lexer cont = lexToken >>= cont

-- | skip characters till a newline is found.
--   We use the fact that Parser = AlexInput
skipOneLineComment :: Parser Token
skipOneLineComment =
  do s <- get
     put (s { lexerInput = skip_ (lexerInput s) })
     lexToken
    where skip_ :: AlexInput -> AlexInput
          skip_ inp =
            case alexGetChar inp of
              Just ('\n', inp') -> inp'
              Just (_   , inp') -> skip_ inp'
              Nothing           -> inp

-- | To fix bug(?) in alex 3.0.1
--   see https://github.com/yihuang/yi/commit/d9222efc16ef82b44f88878af34b41737000a455
first :: (a -> b) -> (a, c) -> (b, c)
first f (a, c) = (f a, c)

alexGetByte :: AlexInput -> Maybe (Word8, AlexInput)
alexGetByte = fmap (first (fromIntegral . ord)) . alexGetChar

skipNestedComment :: Parser Token
skipNestedComment =
  do s <- get
     inp' <- skip_ 1 (lexerInput s)
     put (s { lexerInput = inp' })
     lexToken
    where
      skip_ :: Int -> AlexInput -> Parser AlexInput
      skip_ 0 inp = return inp
      skip_ n (AlexInput { lexPos = p,
                           lexInput = ('{':'-':s) }) =
        skip_ (n + 1) (AlexInput { lexPos = advancePos p 2,
                                   lexInput = s,
                                   lexPrevChar = '-' })
      skip_ n (AlexInput { lexPos = p,
                           lexInput = ('-':'}':s) }) =
        skip_ (n - 1) (AlexInput { lexPos = advancePos p 2,
                                   lexInput = s,
                                   lexPrevChar = '}' })
      skip_ n inp =
        case alexGetChar inp of
          Just (_   , inp') -> skip_ n inp'
          Nothing           -> fail "Open nested comment"

}
